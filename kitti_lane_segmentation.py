import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import cv2
import time
import pickle
from scipy.spatial.transform import Rotation
import open3d as o3d
import glob
import argparse
from pathlib import Path

class KITTILaneSegmentation:
    def __init__(self, base_path, dataset_prefix, pose_file=None):
        self.base_path = Path(base_path)
        self.date = dataset_prefix
        self.drive = f'{dataset_prefix}_sync'
        
        # ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self.data_path = self.base_path / 'data' / self.drive
        self.calib_path = self.base_path / 'calibration' / self.date
        
        self.image_path = self.data_path / 'image_02' / 'data'
        self.velodyne_path = self.data_path / 'velodyne_points' / 'data'
        
        # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        self.image_files = sorted(glob.glob(str(self.image_path / '*.png')))
        self.velodyne_files = sorted(glob.glob(str(self.velodyne_path / '*.bin')))
        
        # ì‚¬ì „ ê³„ì‚°ëœ pose ë¡œë“œ
        self.pose_file = pose_file
        self.precomputed_poses = None
        if pose_file:
            self.load_precomputed_poses(pose_file)
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
        self.load_calibration()
        
        # ì´ë¯¸ì§€ í¬ê¸°ëŠ” ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ì½ì–´ì„œ í™•ì¸
        if self.image_files:
            sample_image = cv2.imread(self.image_files[0])
            self.image_height, self.image_width = sample_image.shape[:2]
            print(f"ì´ë¯¸ì§€ í¬ê¸°: {self.image_width} x {self.image_height}")
        else:
            # ê¸°ë³¸ê°’ (KITTI í‘œì¤€ í¬ê¸°)
            self.image_width, self.image_height = 1242, 375
            
        # ROI ì„¤ì • (ì´ë¯¸ì§€ í•˜ë‹¨ ì ˆë°˜)
        half_height = self.image_height // 2
        self.roi_vertices = np.array([
            [(0, self.image_height), (self.image_width, self.image_height), 
             (self.image_width, half_height), (0, half_height)]
        ], dtype=np.int32)
        
        print(f"ROI ì„¤ì •: y={half_height} ~ {self.image_height} (í•˜ë‹¨ ì ˆë°˜)")
    
    def load_calibration(self):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        try:
            # ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
            calib_path = self.calib_path / 'calib_cam_to_cam.txt'
            with open(calib_path, 'r') as f:
                calib_data = f.readlines()
            
            # P2 (ì¹´ë©”ë¼ í”„ë¡œì ì…˜ í–‰ë ¬)
            P2_line = [line for line in calib_data if line.startswith('P_rect_02')][0]
            self.P2 = np.array([float(x) for x in P2_line.strip().split()[1:13]]).reshape(3, 4)
            
            # R0_rect (ì •ê·œí™” í–‰ë ¬)
            R0_line = [line for line in calib_data if line.startswith('R_rect_02')][0]
            self.R0_rect = np.array([float(x) for x in R0_line.strip().split()[1:10]]).reshape(3, 3)
            
            # ë¼ì´ë‹¤->ì¹´ë©”ë¼ ë³€í™˜ í–‰ë ¬
            velo_to_cam_path = self.calib_path / 'calib_velo_to_cam.txt'
            with open(velo_to_cam_path, 'r') as f:
                velo_to_cam_data = f.readlines()
            
            R_line = [line for line in velo_to_cam_data if line.startswith('R:')][0]
            self.R = np.array([float(x) for x in R_line.strip().split()[1:10]]).reshape(3, 3)
            
            T_line = [line for line in velo_to_cam_data if line.startswith('T:')][0]
            self.T = np.array([float(x) for x in T_line.strip().split()[1:4]]).reshape(3, 1)
            
            self.Tr_velo_to_cam = np.hstack((self.R, self.T))
            
            print("âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def load_precomputed_poses(self, pose_file):
        """ì‚¬ì „ ê³„ì‚°ëœ pose íŒŒì¼ ë¡œë“œ"""
        try:
            with open(pose_file, 'rb') as f:
                self.precomputed_poses = pickle.load(f)
            print(f"âœ… Pose íŒŒì¼ ë¡œë“œ ì„±ê³µ: {pose_file}")
        except Exception as e:
            print(f"âŒ Pose íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def detect_white_lanes(self, image):
        """ë°ì€ ì•„ìŠ¤íŒ”íŠ¸ì—ì„œ í•˜ì–€ìƒ‰ ì°¨ì„  ê²€ì¶œ"""
        # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # 2. ë°ì€ ì•„ìŠ¤íŒ”íŠ¸ë¥¼ ê³ ë ¤í•œ ë†’ì€ ì„ê³„ê°’ ì‚¬ìš©
        # ë§¤ìš° ë°ì€ í”½ì…€ë§Œ ì°¨ì„ ìœ¼ë¡œ ê°„ì£¼
        white_mask1 = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]  # ë†’ì€ ì„ê³„ê°’
        white_mask2 = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)[1]  # ë§¤ìš° ë†’ì€ ì„ê³„ê°’
        white_mask3 = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)[1]  # ê·¹ë„ë¡œ ë†’ì€ ì„ê³„ê°’
        
        # ëª¨ë“  ë§ˆìŠ¤í¬ ê²°í•©
        white_mask = cv2.bitwise_or(white_mask1, white_mask2)
        white_mask = cv2.bitwise_or(white_mask, white_mask3)
        
        # 3. ROI ì ìš© (ì´ë¯¸ì§€ í•˜ë‹¨ ì ˆë°˜) - ë™ì  í¬ê¸°
        roi_mask = np.zeros_like(white_mask)
        cv2.fillPoly(roi_mask, self.roi_vertices, 255)
        white_mask_roi = cv2.bitwise_and(white_mask, roi_mask)
        
        # 4. ê°€ë²¼ìš´ ë…¸ì´ì¦ˆ ì œê±°
        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        white_mask_roi = cv2.morphologyEx(white_mask_roi, cv2.MORPH_OPEN, kernel_small)
        white_mask_roi = cv2.morphologyEx(white_mask_roi, cv2.MORPH_CLOSE, kernel_small)
        
        # 5. ì—£ì§€ ê²€ì¶œ
        # ì›ë³¸ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì—ì„œ ì§ì ‘ ì—£ì§€ ê²€ì¶œ (ROI ì ìš©)
        gray_roi = cv2.bitwise_and(gray, roi_mask)
        gray_blur = cv2.GaussianBlur(gray_roi, (5, 5), 0)
        edges = cv2.Canny(gray_blur, 100, 200)  # ë†’ì€ ì„ê³„ê°’ìœ¼ë¡œ í™•ì‹¤í•œ ì—£ì§€ë§Œ
        
        # ë§ˆìŠ¤í¬ ê¸°ë°˜ ì—£ì§€ë„ ì¶”ê°€
        mask_blur = cv2.GaussianBlur(white_mask_roi, (3, 3), 0)
        mask_edges = cv2.Canny(mask_blur, 50, 150)
        
        # ë‘ ì—£ì§€ ê²°í•©
        final_edges = cv2.bitwise_or(edges, mask_edges)
        
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        white_pixels = np.sum(white_mask > 0)
        roi_white_pixels = np.sum(white_mask_roi > 0)
        edge_pixels = np.sum(final_edges > 0)
        
        # ROI ì˜ì—­ì˜ í‰ê·  ë°ê¸°ë„ ì¶œë ¥
        roi_area = gray[roi_mask > 0]
        avg_brightness = np.mean(roi_area) if len(roi_area) > 0 else 0
        
        print(f"  ë””ë²„ê¹…: ROI í‰ê· ë°ê¸°={avg_brightness:.1f}, í°ìƒ‰ í”½ì…€={white_pixels}, ROI í°ìƒ‰ í”½ì…€={roi_white_pixels}, ì—£ì§€ í”½ì…€={edge_pixels}")
        
        return white_mask, white_mask_roi, final_edges
    
    def extract_lane_lines(self, edges):
        """ì°¨ì„  ë¼ì¸ ì¶”ì¶œ (ë§¤ìš° ê´€ëŒ€í•œ ì„¤ì •)"""
        # í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ì§ì„  ê²€ì¶œ (ë§¤ìš° ê´€ëŒ€í•œ íŒŒë¼ë¯¸í„°)
        lines = cv2.HoughLinesP(
            edges, 
            rho=1, 
            theta=np.pi/180, 
            threshold=10,      # ë§¤ìš° ë‚®ì€ ì„ê³„ê°’
            minLineLength=20,  # ë§¤ìš° ì§§ì€ ë¼ì¸ë„ í—ˆìš©
            maxLineGap=50      # í° ê°­ë„ í—ˆìš©
        )
        
        # ë””ë²„ê¹… ì •ë³´
        if lines is not None:
            print(f"  ë””ë²„ê¹…: í—ˆí”„ ë³€í™˜ìœ¼ë¡œ {len(lines)}ê°œ ë¼ì¸ ê²€ì¶œ")
            
            # ê²€ì¶œëœ ë¼ì¸ë“¤ì˜ ê¸°ìš¸ê¸° ë¶„í¬ í™•ì¸
            slopes = []
            for line in lines:
                x1, y1, x2, y2 = line[0]
                if x2 - x1 != 0:
                    slope = (y2 - y1) / (x2 - x1)
                    slopes.append(slope)
            
            if slopes:
                print(f"  ë””ë²„ê¹…: ê¸°ìš¸ê¸° ë²”ìœ„ = {min(slopes):.2f} ~ {max(slopes):.2f}")
        else:
            print(f"  ë””ë²„ê¹…: í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ë¼ì¸ì„ ì°¾ì§€ ëª»í•¨")
        
        # ë¼ì¸ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if lines is None:
            return [], []
        
        # ê¸°ìš¸ê¸°ë¡œ ì¢Œì¸¡/ìš°ì¸¡ ì°¨ì„  ë¶„ë¥˜ (ë§¤ìš° ê´€ëŒ€í•œ ë²”ìœ„)
        left_lines = []
        right_lines = []
        
        for line in lines:
            x1, y1, x2, y2 = line[0]
            if x2 - x1 == 0:  # ìˆ˜ì§ì„  ì œì™¸
                continue
            slope = (y2 - y1) / (x2 - x1)
            
            # ê¸°ìš¸ê¸° í•„í„°ë§ (ë§¤ìš° ê´€ëŒ€í•˜ê²Œ - ê±°ì˜ ëª¨ë“  ê¸°ìš¸ê¸° í—ˆìš©)
            if abs(slope) < 0.1:  # ë„ˆë¬´ ìˆ˜í‰ì¸ ê²ƒë§Œ ì œì™¸
                continue
                
            if slope < 0:  # ì¢Œì¸¡ ì°¨ì„  (ìŒì˜ ê¸°ìš¸ê¸°)
                left_lines.append(line[0])
            else:  # ìš°ì¸¡ ì°¨ì„  (ì–‘ì˜ ê¸°ìš¸ê¸°)
                right_lines.append(line[0])
        
        print(f"  ë””ë²„ê¹…: ì¢Œì¸¡ ì°¨ì„  {len(left_lines)}ê°œ, ìš°ì¸¡ ì°¨ì„  {len(right_lines)}ê°œ ê²€ì¶œ")
        
        # ê¸°ìš¸ê¸°ë³„ë¡œ ë¼ì¸ë“¤ ì¶œë ¥ (ì²˜ìŒ 5ê°œë§Œ)
        if left_lines:
            print(f"  ì¢Œì¸¡ ì°¨ì„  ì˜ˆì‹œ: {left_lines[:3]}")
        if right_lines:
            print(f"  ìš°ì¸¡ ì°¨ì„  ì˜ˆì‹œ: {right_lines[:3]}")
        
        return left_lines, right_lines
    
    def fit_lane_lines(self, lines, image_shape):
        """ì°¨ì„  ë¼ì¸ í”¼íŒ…"""
        if len(lines) == 0:
            return None
        
        # ëª¨ë“  ì ë“¤ì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ í•©ì¹˜ê¸°
        x_coords = []
        y_coords = []
        
        for line in lines:
            x1, y1, x2, y2 = line
            x_coords.extend([x1, x2])
            y_coords.extend([y1, y2])
        
        # ë‹¤í•­ì‹ í”¼íŒ… (1ì°¨)
        if len(x_coords) >= 2:
            coeffs = np.polyfit(y_coords, x_coords, 1)
            
            # y ì¢Œí‘œ ë²”ìœ„ ì„¤ì •
            y_start = int(image_shape[0] * 0.6)  # ì´ë¯¸ì§€ í•˜ë‹¨ 40%
            y_end = image_shape[0]
            
            # í”¼íŒ…ëœ ë¼ì¸ì˜ ì‹œì‘ì ê³¼ ëì  ê³„ì‚°
            x_start = int(coeffs[0] * y_start + coeffs[1])
            x_end = int(coeffs[0] * y_end + coeffs[1])
            
            return [(x_start, y_start, x_end, y_end)]
        
        return None
    
    def segment_lanes(self, image):
        """ì°¨ì„  ê²€ì¶œ ë° ë¶„í• """
        # 1. í•˜ì–€ìƒ‰ ì°¨ì„  ê²€ì¶œ
        white_mask, white_mask_roi, edges = self.detect_white_lanes(image)
        
        # 2. ì°¨ì„  ë¼ì¸ ì¶”ì¶œ
        left_lines, right_lines = self.extract_lane_lines(edges)
        
        # 3. ì°¨ì„  ë¼ì¸ í”¼íŒ…
        fitted_left = self.fit_lane_lines(left_lines, image.shape)
        fitted_right = self.fit_lane_lines(right_lines, image.shape)
        
        # 4. ìµœì¢… ì°¨ì„  ë§ˆìŠ¤í¬ ìƒì„±
        lane_mask = np.zeros_like(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY))
        
        # ê²€ì¶œëœ ë¼ì¸ë“¤ ê·¸ë¦¬ê¸°
        all_lines = []
        if fitted_left:
            all_lines.extend(fitted_left)
            for line in fitted_left:
                x1, y1, x2, y2 = line
                cv2.line(lane_mask, (x1, y1), (x2, y2), 255, 3)
        
        if fitted_right:
            all_lines.extend(fitted_right)
            for line in fitted_right:
                x1, y1, x2, y2 = line
                cv2.line(lane_mask, (x1, y1), (x2, y2), 255, 3)
        
        return white_mask, lane_mask, all_lines
    
    def extract_lane_boundaries(self, lane_mask, lines):
        """ì°¨ì„  ê²½ê³„ì„  ì¶”ì¶œ"""
        # ìŠ¤ì¼ˆë ˆí†¤ ì¶”ì¶œ
        if np.any(lane_mask):
            skeleton = cv2.ximgproc.thinning(lane_mask)
        else:
            skeleton = lane_mask.copy()
        
        return skeleton, lines

    def visualize_lane_segmentation(self, frame_idx, show_lidar=True):
        """í”„ë ˆì„ë³„ ì°¨ì„  ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        image_path = self.image_path / f'{frame_idx:010d}.png'
        image = cv2.imread(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # 2. ì°¨ì„  ê²€ì¶œ (ì›ì‹œ ê²°ê³¼ë§Œ)
        white_mask, white_mask_roi, edges = self.detect_white_lanes(image)
        
        # 3. ì‹œê°í™” - í”„ë ˆì„ë³„ ì°¨ì„  ê²€ì¶œ ê²°ê³¼
        plt.figure(figsize=(15, 10))
        
        # 3.1 ì›ë³¸ ì´ë¯¸ì§€ (ROI í‘œì‹œ)
        plt.subplot(221)
        plt.imshow(image)
        roi_overlay = image.copy()
        cv2.polylines(roi_overlay, self.roi_vertices, True, (255, 0, 0), 3)
        plt.imshow(roi_overlay)
        plt.title('Original Image with ROI', fontsize=14)
        plt.axis('off')
        
        # 3.2 ë°ê¸° ì„ê³„ê°’ ê²°ê³¼
        plt.subplot(222)
        plt.imshow(white_mask, cmap='gray')
        plt.title('Brightness Threshold', fontsize=14)
        plt.axis('off')
        
        # 3.3 ROI ì ìš© ê²°ê³¼
        plt.subplot(223)
        plt.imshow(white_mask_roi, cmap='gray')
        plt.title('ROI Applied', fontsize=14)
        plt.axis('off')
        
        # 3.4 ì›ë³¸ì— ì°¨ì„  ì˜¤ë²„ë ˆì´
        plt.subplot(224)
        plt.imshow(image)
        
        # ì°¨ì„  ê²€ì¶œ ê²°ê³¼ë¥¼ ë…¸ë€ìƒ‰ìœ¼ë¡œ ì˜¤ë²„ë ˆì´
        lane_overlay = np.zeros_like(image)
        lane_overlay[white_mask_roi > 0] = [255, 255, 0]  # ë…¸ë€ìƒ‰
        
        # ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´
        result = cv2.addWeighted(image, 0.7, lane_overlay, 0.3, 0)
        plt.imshow(result)
        plt.title('Lane Detection Overlay', fontsize=14)
        plt.axis('off')
        
        plt.tight_layout()
        
        # 4. ê²°ê³¼ ì €ì¥
        results_dir = Path('results_lane') / self.date
        os.makedirs(results_dir, exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f'kitti_lane_detection_frame{frame_idx}_{timestamp}.png'
        filepath = results_dir / filename
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"âœ… í”„ë ˆì„ {frame_idx} ì°¨ì„  ê²€ì¶œ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")
        
        # ê²€ì¶œ í†µê³„ ì¶œë ¥
        white_pixels = np.sum(white_mask > 0)
        roi_white_pixels = np.sum(white_mask_roi > 0)
        edge_pixels = np.sum(edges > 0)
        
        print(f"í”„ë ˆì„ {frame_idx} ê²€ì¶œ í†µê³„:")
        print(f"  - ë°ê¸° ê¸°ë°˜ í°ìƒ‰ í”½ì…€: {white_pixels}ê°œ")
        print(f"  - ROI ì ìš© í°ìƒ‰ í”½ì…€: {roi_white_pixels}ê°œ")
        print(f"  - ì—£ì§€ í”½ì…€: {edge_pixels}ê°œ")
        
        # 5. ë¼ì´ë‹¤ í¬ì¸íŠ¸ì™€ì˜ ìœµí•© (ì„ íƒì )
        if show_lidar:
            self.visualize_lidar_fusion(frame_idx, white_mask_roi)
    
    def visualize_lidar_fusion(self, frame_idx, lane_mask):
        """ë¼ì´ë‹¤ í¬ì¸íŠ¸ì™€ ì°¨ì„  ê²€ì¶œ ê²°ê³¼ ìœµí•© ì‹œê°í™”"""
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        image_path = self.image_path / f'{frame_idx:010d}.png'
        image = cv2.imread(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # 2. ë¼ì´ë‹¤ í¬ì¸íŠ¸ ë¡œë“œ
        points = np.fromfile(self.velodyne_files[frame_idx], dtype=np.float32).reshape(-1, 4)
        
        # 3. í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        points_homo = np.ones((len(points), 4))
        points_homo[:, :3] = points[:, :3]
        
        # ë¼ì´ë‹¤ -> ì¹´ë©”ë¼ ë³€í™˜
        points_cam = (self.Tr_velo_to_cam @ points_homo.T).T
        
        # ì •ê·œí™”
        points_rect = (self.R0_rect @ points_cam[:, :3].T).T
        
        # ì¹´ë©”ë¼ ì¢Œí‘œë¥¼ ì´ë¯¸ì§€ í‰ë©´ì— íˆ¬ì˜
        points_proj = (self.P2 @ np.vstack((points_rect.T, np.ones(len(points_rect))))).T
        points_proj = points_proj[:, :2] / points_proj[:, 2:]
        
        # ì´ë¯¸ì§€ ë‚´ë¶€ì— ìˆëŠ” í¬ì¸íŠ¸ë§Œ ì„ íƒ
        mask = (points_proj[:, 0] >= 0) & (points_proj[:, 0] < image.shape[1]) & \
               (points_proj[:, 1] >= 0) & (points_proj[:, 1] < image.shape[0]) & \
               (points_cam[:, 2] > 0)
        
        points_proj = points_proj[mask]
        points_cam = points_cam[mask]
        
        # 4. ì‹œê°í™”
        plt.figure(figsize=(15, 5))
        
        # 4.1 ì›ë³¸ ì´ë¯¸ì§€
        plt.subplot(131)
        plt.imshow(image)
        plt.title('Original Image', fontsize=14)
        plt.axis('off')
        
        # 4.2 ë¼ì´ë‹¤ í¬ì¸íŠ¸ ì˜¤ë²„ë ˆì´
        plt.subplot(132)
        plt.imshow(image)
        
        # ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ ë§¤í•‘
        distances = np.linalg.norm(points_cam[:, :3], axis=1)
        colors = plt.cm.jet(distances / np.max(distances))
        
        # í¬ì¸íŠ¸ í¬ê¸°ëŠ” ê±°ë¦¬ì— ë°˜ë¹„ë¡€
        sizes = 30 / (distances + 1)
        
        plt.scatter(points_proj[:, 0], points_proj[:, 1], c=colors, s=sizes, alpha=0.6)
        plt.title('LiDAR Points', fontsize=14)
        plt.axis('off')
        
        # 4.3 ì°¨ì„ ê³¼ ë¼ì´ë‹¤ í¬ì¸íŠ¸ ìœµí•©
        plt.subplot(133)
        plt.imshow(image)
        
        # ì°¨ì„  ê²€ì¶œ ê²°ê³¼ë¥¼ ë…¸ë€ìƒ‰ìœ¼ë¡œ ì˜¤ë²„ë ˆì´
        lane_overlay = np.zeros_like(image)
        lane_overlay[lane_mask > 0] = [255, 255, 0]  # ë…¸ë€ìƒ‰
        
        # ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´
        result = cv2.addWeighted(image, 0.6, lane_overlay, 0.4, 0)
        plt.imshow(result)
        
        # ë¼ì´ë‹¤ í¬ì¸íŠ¸ ì˜¤ë²„ë ˆì´
        plt.scatter(points_proj[:, 0], points_proj[:, 1], c=colors, s=sizes, alpha=0.5)
        plt.title('Lane + LiDAR Fusion', fontsize=14)
        plt.axis('off')
        
        plt.tight_layout()
        
        # 5. ê²°ê³¼ ì €ì¥
        results_dir = Path('results') / self.date
        os.makedirs(results_dir, exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f'kitti_lidar_fusion_frame{frame_idx}_{timestamp}.png'
        filepath = results_dir / filename
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"âœ… í”„ë ˆì„ {frame_idx} ë¼ì´ë‹¤ ìœµí•© ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

    def get_pose_from_precomputed(self, frame_idx, pose_type='gt'):
        """ì‚¬ì „ ê³„ì‚°ëœ poseì—ì„œ íŠ¹ì • í”„ë ˆì„ì˜ poseë¥¼ ê°€ì ¸ì˜´"""
        if self.precomputed_poses is None:
            return None
            
        try:
            if pose_type == 'gt':
                return self.precomputed_poses['gt_poses'][frame_idx]
            elif pose_type == 'icp':
                return self.precomputed_poses['icp_poses'][frame_idx]
            else:
                print(f"ê²½ê³ : ì•Œ ìˆ˜ ì—†ëŠ” pose íƒ€ì…: {pose_type}")
                return None
        except (KeyError, IndexError) as e:
            print(f"ê²½ê³ : í”„ë ˆì„ {frame_idx}ì˜ poseë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return None

    def project_lane_to_3d(self, white_mask_roi, frame_idx):
        """ì°¨ì„  ê²€ì¶œ ê²°ê³¼ë¥¼ ë¼ì´ë‹¤ í¬ì¸íŠ¸ì™€ ë§¤í•‘í•˜ì—¬ 3D ì¢Œí‘œë¡œ ë³€í™˜"""
        # 1. ë¼ì´ë‹¤ í¬ì¸íŠ¸ ë¡œë“œ
        if frame_idx >= len(self.velodyne_files):
            return None
            
        points = np.fromfile(self.velodyne_files[frame_idx], dtype=np.float32).reshape(-1, 4)
        points_xyz = points[:, :3]
        
        # 2. ë¼ì´ë‹¤ í¬ì¸íŠ¸ë¥¼ ì´ë¯¸ì§€ í‰ë©´ì— íˆ¬ì˜
        points_homo = np.ones((len(points_xyz), 4))
        points_homo[:, :3] = points_xyz
        
        # ë¼ì´ë‹¤ -> ì¹´ë©”ë¼ ë³€í™˜
        points_cam = (self.Tr_velo_to_cam @ points_homo.T).T
        
        # ì •ê·œí™”
        points_rect = (self.R0_rect @ points_cam[:, :3].T).T
        
        # ì¹´ë©”ë¼ ì¢Œí‘œë¥¼ ì´ë¯¸ì§€ í‰ë©´ì— íˆ¬ì˜
        points_proj = (self.P2 @ np.vstack((points_rect.T, np.ones(len(points_rect))))).T
        points_proj = points_proj[:, :2] / points_proj[:, 2:]
        
        # ì´ë¯¸ì§€ ë‚´ë¶€ì— ìˆëŠ” í¬ì¸íŠ¸ë§Œ ì„ íƒ
        mask = (points_proj[:, 0] >= 0) & (points_proj[:, 0] < self.image_width) & \
               (points_proj[:, 1] >= 0) & (points_proj[:, 1] < self.image_height) & \
               (points_cam[:, 2] > 0)  # ì¹´ë©”ë¼ ì•ìª½ì— ìˆëŠ” í¬ì¸íŠ¸ë§Œ
        
        valid_points_proj = points_proj[mask]
        valid_points_xyz = points_xyz[mask]
        
        if len(valid_points_proj) == 0:
            return None
        
        # 3. ì°¨ì„  ë§ˆìŠ¤í¬ ì˜ì—­ì— í•´ë‹¹í•˜ëŠ” ë¼ì´ë‹¤ í¬ì¸íŠ¸ ì°¾ê¸°
        lane_points_3d = []
        
        # íˆ¬ì˜ëœ ë¼ì´ë‹¤ í¬ì¸íŠ¸ë“¤ ì¤‘ì—ì„œ ì°¨ì„  ë§ˆìŠ¤í¬ ì˜ì—­ì— ìˆëŠ” ê²ƒë“¤ ì„ íƒ
        for i, (u, v) in enumerate(valid_points_proj):
            u_int, v_int = int(round(u)), int(round(v))
            
            # ì°¨ì„  ë§ˆìŠ¤í¬ ì˜ì—­ í™•ì¸ (ì£¼ë³€ í”½ì…€ë„ í™•ì¸í•˜ì—¬ ë” ê´€ëŒ€í•˜ê²Œ)
            window_size = 3  # 3x3 ìœˆë„ìš°
            found_lane = False
            
            for du in range(-window_size, window_size + 1):
                for dv in range(-window_size, window_size + 1):
                    check_u = u_int + du
                    check_v = v_int + dv
                    
                    if (0 <= check_u < self.image_width and 
                        0 <= check_v < self.image_height and
                        white_mask_roi[check_v, check_u] > 0):
                        found_lane = True
                        break
                        
                if found_lane:
                    break
            
            if found_lane:
                lane_points_3d.append(valid_points_xyz[i])
        
        if len(lane_points_3d) == 0:
            return None
        
        lane_points_3d = np.array(lane_points_3d)
        
        # 4. ë¼ì´ë‹¤ ì¢Œí‘œë¥¼ ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜
        if self.precomputed_poses is not None:
            pose = self.get_pose_from_precomputed(frame_idx, pose_type='gt')
            if pose is not None:
                # 4x4 ë³€í™˜ í–‰ë ¬
                transform = np.eye(4)
                transform[:3, :3] = pose[:3, :3]
                transform[:3, 3] = pose[:3, 3]
                
                # ë™ì°¨ ì¢Œí‘œë¡œ ë³€í™˜
                lane_homo = np.hstack([lane_points_3d, np.ones((len(lane_points_3d), 1))])
                
                # ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜
                world_points = (transform @ lane_homo.T).T
                world_3d = world_points[:, :3]
                
                # í•„í„°ë§: ì°¨ëŸ‰ ì£¼ë³€ í•©ë¦¬ì ì¸ ê±°ë¦¬ ë‚´ì˜ ì ë“¤ë§Œ
                distances = np.linalg.norm(world_3d[:, :2] - pose[:2, 3], axis=1)
                height_diff = np.abs(world_3d[:, 2] - pose[2, 3])
                
                valid_mask = (distances < 50.0) & (height_diff < 3.0) & (distances > 1.0)
                
                if np.any(valid_mask):
                    return world_3d[valid_mask]
        
        return None

    def visualize_trajectory_with_lanes(self, pointcloud_path, trajectory_path):
        """ê¶¤ì ê³¼ ì°¨ì„  ê²€ì¶œ ê²°ê³¼ë¥¼ í•¨ê»˜ ì‹œê°í™”"""
        # 1. ê¶¤ì  ë¡œë“œ
        trajectory_data = np.load(trajectory_path)
        gt_trajectory = trajectory_data['gt_trajectory']
        icp_trajectory = trajectory_data['icp_trajectory']
        
        # ê¶¤ì  ë°ì´í„° í¬ê¸° í™•ì¸
        num_trajectory_points = len(gt_trajectory)
        print(f"ê¶¤ì  ë°ì´í„° í¬ê¸°: {num_trajectory_points}")
        
        # 2. ì‹œê°í™”
        plt.figure(figsize=(20, 8))
        
        # 2.1 ê¶¤ì ë§Œ í‘œì‹œ
        plt.subplot(121)
        plt.plot(gt_trajectory[:, 0], gt_trajectory[:, 1], 'r-', linewidth=3, label='GT Trajectory', alpha=0.9)
        plt.plot(icp_trajectory[:, 0], icp_trajectory[:, 1], 'b-', linewidth=3, label='ICP Trajectory', alpha=0.9)
        plt.scatter(gt_trajectory[0, 0], gt_trajectory[0, 1], c='green', s=200, marker='o', label='Start', zorder=5)
        plt.scatter(gt_trajectory[-1, 0], gt_trajectory[-1, 1], c='red', s=200, marker='X', label='End', zorder=5)
        plt.title('Vehicle Trajectory', fontsize=16, fontweight='bold')
        plt.xlabel('X Position (m)', fontsize=14)
        plt.ylabel('Y Position (m)', fontsize=14)
        plt.grid(True, alpha=0.3)
        plt.axis('equal')
        plt.legend(fontsize=12)
        
        # 2.2 ì°¨ì„  ê²€ì¶œ ê²°ê³¼ ì˜¤ë²„ë ˆì´
        plt.subplot(122)
        plt.plot(gt_trajectory[:, 0], gt_trajectory[:, 1], 'r-', linewidth=3, label='GT Trajectory', alpha=0.9)
        
        # ì°¨ì„  ê²€ì¶œ ê²°ê³¼ë¥¼ ì˜¤ë²„ë ˆì´
        # 10í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬
        max_frames = min(num_trajectory_points, len(self.image_files))
        frame_indices = np.arange(0, max_frames, 10)  # 10í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬
        print(f"ğŸ” ì°¨ì„  ê²€ì¶œ ì‹œì‘: 0ë¶€í„° {max_frames-1}ê¹Œì§€ 10í”„ë ˆì„ ê°„ê²©ìœ¼ë¡œ ì´ {len(frame_indices)}ê°œ í”„ë ˆì„ ì²˜ë¦¬")
        
        all_lane_points = []
        successful_frames = 0
        
        for i, frame_idx in enumerate(frame_indices):
            if i % 5 == 0:  # 5í”„ë ˆì„ë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
                print(f"â³ ì§„í–‰ìƒí™©: {i+1}/{len(frame_indices)} ({(i+1)/len(frame_indices)*100:.1f}%)")
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            if frame_idx >= len(self.image_files):
                continue
                
            image_path = self.image_files[frame_idx]
            if not os.path.exists(image_path):
                continue
                
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ì°¨ì„  ê²€ì¶œ
            white_mask, white_mask_roi, edges = self.detect_white_lanes(image)
            
            # ì°¨ì„  ê²€ì¶œ ê²°ê³¼ë¥¼ 3D ê³µê°„ì— íˆ¬ì˜
            lane_points_3d = self.project_lane_to_3d(white_mask_roi, frame_idx)
            if lane_points_3d is not None and len(lane_points_3d) > 0:
                all_lane_points.append(lane_points_3d)
                successful_frames += 1
                
                # ì°¨ì„  í¬ì¸íŠ¸ë¥¼ ë…¸ë€ìƒ‰ ê³„ì—´ë¡œ í‘œì‹œ
                plt.scatter(lane_points_3d[:, 0], lane_points_3d[:, 1], 
                          c='yellow', s=3, alpha=0.7, 
                          label='Lane Detection' if successful_frames == 1 else "")
                
                if i % 10 == 0:  # 10í”„ë ˆì„ë§ˆë‹¤ ìƒì„¸ ì •ë³´ ì¶œë ¥
                    print(f"  âœ… í”„ë ˆì„ {frame_idx}: {len(lane_points_3d)}ê°œ ì°¨ì„  í¬ì¸íŠ¸ ê²€ì¶œë¨")
        
        print(f"ğŸ¯ ì°¨ì„  ê²€ì¶œ ì™„ë£Œ: {successful_frames}/{len(frame_indices)} í”„ë ˆì„ì—ì„œ ì„±ê³µ")
        
        # ì‹œì‘ì ê³¼ ëì  í‘œì‹œ
        plt.scatter(gt_trajectory[0, 0], gt_trajectory[0, 1], c='green', s=200, marker='o', label='Start', zorder=5)
        plt.scatter(gt_trajectory[-1, 0], gt_trajectory[-1, 1], c='red', s=200, marker='X', label='End', zorder=5)
        
        plt.title('Trajectory with Lane Detection (BEV)', fontsize=16, fontweight='bold')
        plt.xlabel('X Position (m)', fontsize=14)
        plt.ylabel('Y Position (m)', fontsize=14)
        plt.grid(True, alpha=0.3)
        plt.axis('equal')
        plt.legend(fontsize=12)
        
        plt.tight_layout()
        
        # ê²°ê³¼ ì €ì¥
        results_dir = Path('results_lane') / self.date
        os.makedirs(results_dir, exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f'kitti_trajectory_lanes_{timestamp}.png'
        filepath = results_dir / filename
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"âœ… ê¶¤ì ê³¼ ì°¨ì„  ê²€ì¶œ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")
        
        # í†µê³„ ì¶œë ¥
        total_lane_points = sum(len(points) for points in all_lane_points)
        print(f"\nğŸ“Š ì°¨ì„  ê²€ì¶œ í†µê³„:")
        print(f"  - ì²˜ë¦¬ëœ í”„ë ˆì„ ìˆ˜: {len(all_lane_points)}")
        print(f"  - ì´ ì°¨ì„  í¬ì¸íŠ¸ ìˆ˜: {total_lane_points}")
        print(f"  - í”„ë ˆì„ë‹¹ í‰ê·  í¬ì¸íŠ¸ ìˆ˜: {total_lane_points/len(all_lane_points) if all_lane_points else 0:.1f}")

def main():
    parser = argparse.ArgumentParser(description='KITTI Lane Segmentation')
    parser.add_argument('--base_path', type=str, 
                      default='KITTI_dataset',
                      help='KITTI ë°ì´í„°ì…‹ì˜ ê¸°ë³¸ ê²½ë¡œ')
    parser.add_argument('--dataset_prefix', type=str,
                      default='2011_09_26_drive_0001',
                      help='ë°ì´í„°ì…‹ í”„ë¦¬í”½ìŠ¤ (ì˜ˆ: 2011_09_26_drive_0001)')
    parser.add_argument('--output_dir', type=str,
                      default='results',
                      help='ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬')
    parser.add_argument('--pose_file', type=str,
                      help='ì‚¬ì „ ê³„ì‚°ëœ pose íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    results_dir = Path(args.output_dir) / args.dataset_prefix
    os.makedirs(results_dir, exist_ok=True)
    
    # pose íŒŒì¼ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    if args.pose_file is None:
        pose_files = sorted(glob.glob(str(Path(args.output_dir) / args.dataset_prefix / 'kitti_poses_*.pkl')))
        if pose_files:
            args.pose_file = pose_files[-1]  # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì‚¬ìš©
            print(f"ìë™ìœ¼ë¡œ ìµœê·¼ pose íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {args.pose_file}")
        else:
            print("ê²½ê³ : pose íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì°¨ì„  ë¶„í•  ëª¨ë¸ ì´ˆê¸°í™”
    lane_seg = KITTILaneSegmentation(args.base_path, args.dataset_prefix, args.pose_file)
    
    print("KITTI Lane Segmentation ì‹œì‘...")
    print(f"ë°ì´í„°ì…‹: {args.dataset_prefix}")
    
    # ì—¬ëŸ¬ í”„ë ˆì„ì— ëŒ€í•´ ì°¨ì„  ë¶„í•  ìˆ˜í–‰ (10í”„ë ˆì„ë§ˆë‹¤)
    max_frames = len(lane_seg.image_files)
    frame_indices = np.arange(0, max_frames, 10)
    print(f"ì²˜ë¦¬í•  í”„ë ˆì„: 0ë¶€í„° {max_frames-1}ê¹Œì§€ 10í”„ë ˆì„ ê°„ê²©ìœ¼ë¡œ ì´ {len(frame_indices)}ê°œ")
    
    for i, frame_idx in enumerate(frame_indices):
        print(f"\ní”„ë ˆì„ {frame_idx} ì²˜ë¦¬ ì¤‘... ({i+1}/{len(frame_indices)})")
        # ë§ˆì§€ë§‰ í”„ë ˆì„ì—ì„œë§Œ ë¼ì´ë‹¤ í¬ì¸íŠ¸ í‘œì‹œ
        show_lidar = (i == len(frame_indices) - 1)
        lane_seg.visualize_lane_segmentation(frame_idx, show_lidar=show_lidar)
    
    # ê¶¤ì ê³¼ ì°¨ì„  ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”
    pointcloud_path = results_dir / 'kitti_gt_pointcloud.pcd'
    trajectory_path = results_dir / 'kitti_trajectory.npz'
    lane_seg.visualize_trajectory_with_lanes(pointcloud_path, trajectory_path)
    
    print(f"\nì™„ë£Œ! ê²°ê³¼ê°€ {results_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 